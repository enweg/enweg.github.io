{"title":"TinyGibbs.jl","markdown":{"yaml":{"title":"TinyGibbs.jl","date":"2023-04-07","categories":["Software"],"description":"`TinyGibbs` is a small Gibbs sampler that makes use of the `AbstractMCMC` interface. It therefore allows for efficient Gibbs sampling including parallel sampling of multiple chains. Additionally, `TinyGibbs` can collect samples in two ways: (1) as a dictionary of tensors where each tensor or (2) as a `MCMCChains.Chains` type. Therefore, all the funcionality of `MCMCChains` can be exploited with `TinyGibbs`."},"containsRefs":false,"markdown":"\n\nWhile learning more about VAR models, I noticed that many of the BayesianEstimation methods rely on Gibbs sampling. Although Julia has many Bayesian libraries, I could not find a Gibbs sampling library that I quite liked. What I wanted was a library that allows one to write a sampler just like one would dicsuss on in a paper. That is, I wanted a sampler that abstract away all the actual computational work and lets me focus on the actual conditional distributions. What I wanted was a sampler that lets me translate a statement like \n\n1. Sample $\\alpha$ from $p(\\alpha | y, x, \\Sigma)$\n2. Sample $\\Sigma$ from $p(\\Sigma | y, x, \\alpha)$\n\ninto a valid sampler. \n\nTinyGibbs is my answer to this need. TinyGibbs introduced a single macro, `@tiny_gibbs` which transforms a statement that is as close as possible to actual pseudo code in papers into a valid sampler. Additionally, by exploiting the functionality provided in [AbstractMCMC](https://github.com/TuringLang/AbstractMCMC.jl) and [MCMCChains](https://github.com/TuringLang/MCMCChains.jl), TinyGibbs is able to sample in parallel and to diagnose the resulting MCMC chains. \n\nFor more information and to try it out, check out the [GitHub repo](https://github.com/enweg/TinyGibbs.jl). Any feedback is greatly appreciated. \n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":2,"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"flatly","title-block-banner":true,"author":"Enrico Wegner","page-layout":"article","title":"TinyGibbs.jl","date":"2023-04-07","categories":["Software"],"description":"`TinyGibbs` is a small Gibbs sampler that makes use of the `AbstractMCMC` interface. It therefore allows for efficient Gibbs sampling including parallel sampling of multiple chains. Additionally, `TinyGibbs` can collect samples in two ways: (1) as a dictionary of tensors where each tensor or (2) as a `MCMCChains.Chains` type. Therefore, all the funcionality of `MCMCChains` can be exploited with `TinyGibbs`."},"extensions":{"book":{"multiFile":true}}}}}