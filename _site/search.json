[
  {
    "objectID": "posts/first_post/post.html",
    "href": "posts/first_post/post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod <- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds <- dat %>% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit > 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn‚Äôt it?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi üëãüèª",
    "section": "",
    "text": "I‚Äôm Enrico. I am a PhD candiate at the School of Business and Economics Maastricht. I am interested in causal and Bayesian macro-econometrics."
  },
  {
    "objectID": "software/SnT/index.html",
    "href": "software/SnT/index.html",
    "title": "SnT_BigTime, SnT_VARS, and BigTime",
    "section": "",
    "text": "As part of my student assistantship to Ines Wilms, I got the chance to develop a set of interactive notebooks introducing VAR models and the BigTime library to which I got to contribute minor parts. These notebooks can be checked out on their respective GitHub repositories.\n\nIntroduction to VARs\nIntroduction to BigTime\nBigTime library"
  },
  {
    "objectID": "software/BayesFluxJulia/index.html",
    "href": "software/BayesFluxJulia/index.html",
    "title": "BayesFlux.jl and BayesFluxR",
    "section": "",
    "text": "BayesFlux.jl extends the famous Flux.jl machine learning library in Julia to Bayesian Neural Networks (BNNs). It is not meant to be suitable for production, but instead is meant to allows easy research on BNNs. As such, I tried to keep all parts flexible and extensible. BayesFlux.jl is used in my master thesis investigating the potential usefulness of Bayesian LSTM networks for financial risk forecasting. It is also currently part of other Master thesis work.\nFor more information, please check out the GitHub repository. Any feedback is appreciated.\nTo make BayesFlux.jl accessible to users that do not know Julia, I also developed an interface to R, called BayesFluxR which can be found here. Both BayesFlux.jl and BayesFluxR are also available on the official Julia repository and CRAN respectively."
  },
  {
    "objectID": "software/TinyGibbs/index.html",
    "href": "software/TinyGibbs/index.html",
    "title": "TinyGibbs.jl",
    "section": "",
    "text": "While learning more about VAR models, I noticed that many of the BayesianEstimation methods rely on Gibbs sampling. Although Julia has many Bayesian libraries, I could not find a Gibbs sampling library that I quite liked. What I wanted was a library that allows one to write a sampler just like one would dicsuss on in a paper. That is, I wanted a sampler that abstract away all the actual computational work and lets me focus on the actual conditional distributions. What I wanted was a sampler that lets me translate a statement like\n\nSample \\(\\alpha\\) from \\(p(\\alpha | y, x, \\Sigma)\\)\nSample \\(\\Sigma\\) from \\(p(\\Sigma | y, x, \\alpha)\\)\n\ninto a valid sampler.\nTinyGibbs is my answer to this need. TinyGibbs introduced a single macro, @tiny_gibbs which transforms a statement that is as close as possible to actual pseudo code in papers into a valid sampler. Additionally, by exploiting the functionality provided in AbstractMCMC and MCMCChains, TinyGibbs is able to sample in parallel and to diagnose the resulting MCMC chains.\nFor more information and to try it out, check out the GitHub repo. Any feedback is greatly appreciated."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\nTinyGibbs.jl\n\n\nTinyGibbs is a small Gibbs sampler that makes use of the AbstractMCMC interface. It therefore allows for efficient Gibbs sampling including parallel sampling of multiple chains. Additionally, TinyGibbs can collect samples in two ways: (1) as a dictionary of tensors where each tensor or (2) as a MCMCChains.Chains type. Therefore, all the funcionality of MCMCChains can be exploited with TinyGibbs.\n\n\n\n\nBayesFlux.jl and BayesFluxR\n\n\nBayesFlux.jl is a small but flexible Baysian Neural Network library. It is work that came out of my Master Thesis and Reseach Assitance. Both were supervised by Nalan Basturk.\n\n\n\n\nSnT_BigTime, SnT_VARS, and BigTime\n\n\nInteractive notebooks introducing VAR models and the BigTime R library.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "This is a dummy blog posts\n\n\n\n\n\n\n\n123\n\n\nSecond Tag\n\n\n\n\nThis is a test post. In this post, I try out different functionalities\n\n\n\n\n\n\nJun 1, 2022\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  }
]